{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08831bed",
   "metadata": {
    "id": "08831bed"
   },
   "source": [
    "# Predicting Readmission Risk with Logistic Regression\n",
    "\n",
    "\n",
    "Time estimate: **20** minutes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad2093",
   "metadata": {
    "id": "46ad2093"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Prepare clinical tabular data for binary classification (readmission yes/no).\n",
    "- Train, evaluate, and interpret a logistic regression model for readmission risk.\n",
    "- Handle class imbalance, perform feature preprocessing, and compute performance metrics (ROC, AUC, precision/recall).\n",
    "- Use calibration plots and decision thresholds to support clinical decision-making.\n",
    "- Report model performance with clarity for clinicians, including limitations and fairness checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff109ce",
   "metadata": {
    "id": "eff109ce"
   },
   "source": [
    "## What you will do in this lab\n",
    "\n",
    "- Simulate a hospital dataset with patient demographics, comorbidities, and inpatient features.\n",
    "- Preprocess data: One-hot encoding, scaling, and train/test split.\n",
    "- Train logistic regression with regularization and examine coefficients.\n",
    "- Evaluate model using confusion matrix, ROC/AUC, precision-recall, and calibration.\n",
    "- Address class imbalance using class weights and simple resampling.\n",
    "- Complete seven consolidated exercises, with hints and solutions provided at the end of the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659d2ce",
   "metadata": {
    "id": "a659d2ce"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Predicting 30-day hospital readmission is a common applied machine-learning task in healthcare. Logistic regression provides a transparent, interpretable baseline model. This lab focuses on end-to-end workflow: data simulation, preprocessing, model training, evaluation, calibration, and reporting—emphasizing interpretability and clinical relevance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562c360",
   "metadata": {
    "id": "8562c360"
   },
   "source": [
    "## About the dataset/environment\n",
    "\n",
    "We will simulate a dataset with the following columns:\n",
    "- `patient_id`, `age`, `sex`, `comorbidity_count`, `length_of_stay`, `num_prior_admissions`, `lab_abnormal_flag`, `discharge_destination` (Home/SNF), and `readmitted_30d` (0/1).\n",
    "The simulated dataset will include moderate class imbalance (readmission ~15%).\n",
    "Tools: Python (pandas, numpy, scikit-learn, matplotlib, seaborn, imbalanced-learn optional).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3eb12",
   "metadata": {
    "id": "12a3eb12"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run the following setup cell to install any needed libraries (especially in Google Colab), import key packages for preprocessing and model evaluation, and configure reproducibility for consistent results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbf8b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15751,
     "status": "ok",
     "timestamp": 1765474810918,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "d0bbf8b5",
    "outputId": "e0188511-6e1b-4d25-91be-57e2a839be63"
   },
   "outputs": [],
   "source": [
    "# Colab compatibility: uncomment installation if needed\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install numpy pandas scikit-learn matplotlib seaborn imbalanced-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report, precision_recall_curve, average_precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Reproducibility\n",
    "RNG = np.random.default_rng(42)\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 60)\n",
    "sns.set(style='whitegrid')\n",
    "print('Setup complete. Running in Colab:', IN_COLAB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233d533",
   "metadata": {},
   "source": [
    "Execute this cell to create a simulated 30-day readmission dataset. The generator constructs clinically meaningful predictors such as age, comorbidities, prior admissions, and discharge status, then assigns readmission probabilities using a controlled logistic process. This ensures you have a realistic, well-behaved dataset for experimenting with preprocessing steps and model evaluation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e78815",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1765474895011,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "b7e78815",
    "outputId": "f1e7ddb1-e9ff-45f4-d685-936615534fcc"
   },
   "outputs": [],
   "source": [
    "# Simulate readmission dataset\n",
    "def simulate_readmission(n_patients=2000, readmit_rate=0.15):\n",
    "    ids = [f\"P{10000+i}\" for i in range(n_patients)]\n",
    "    age = np.clip(np.random.normal(65, 14, size=n_patients).astype(int), 18, 95)\n",
    "    sex = np.random.choice(['M','F'], size=n_patients, p=[0.52,0.48])\n",
    "    comorbidity_count = np.random.poisson(2, size=n_patients)\n",
    "    length_of_stay = np.clip(np.random.exponential(4, size=n_patients).astype(int)+1, 1, 60)\n",
    "    num_prior_adm = np.random.poisson(1, size=n_patients)\n",
    "    lab_abnormal_flag = np.random.binomial(1, 0.18, size=n_patients)\n",
    "    discharge_destination = np.random.choice(['Home','SNF'], size=n_patients, p=[0.85,0.15])\n",
    "    # base log-odds\n",
    "    logits = -2.0 + 0.02*(age-65) + 0.4*lab_abnormal_flag + 0.25*(comorbidity_count) + 0.08*(length_of_stay) + 0.3*(discharge_destination=='SNF') + 0.15*(num_prior_adm)\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    # calibrate to achieve approx readmit_rate\n",
    "    probs = probs * (readmit_rate / probs.mean())\n",
    "    probs = np.clip(probs, 0.01, 0.9)\n",
    "    readmitted = np.random.binomial(1, probs)\n",
    "    df = pd.DataFrame({\n",
    "        'patient_id': ids,\n",
    "        'age': age,\n",
    "        'sex': sex,\n",
    "        'comorbidity_count': comorbidity_count,\n",
    "        'length_of_stay': length_of_stay,\n",
    "        'num_prior_admissions': num_prior_adm,\n",
    "        'lab_abnormal_flag': lab_abnormal_flag,\n",
    "        'discharge_destination': discharge_destination,\n",
    "        'readmitted_30d': readmitted\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = simulate_readmission(n_patients=2000, readmit_rate=0.15)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb1d055",
   "metadata": {
    "id": "6fb1d055"
   },
   "source": [
    "## Step 1: Inspect and understand class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a929812",
   "metadata": {
    "id": "5a929812"
   },
   "source": [
    "Basic inspection and class balance.\n",
    "\n",
    "Run this cell to inspect the structure and quality of the simulated readmission dataset. You will confirm the number of rows and columns, review variable data types, compute descriptive statistics, and check the overall 30-day readmission rate before beginning model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3366c51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765474899449,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "e3366c51",
    "outputId": "1f7fcd49-e135-400c-bf01-06a0aa2902c9"
   },
   "outputs": [],
   "source": [
    "print('Rows, Columns:', df.shape)\n",
    "print(df.dtypes)\n",
    "df.describe().T\n",
    "print('\\nReadmission counts:\\n', df['readmitted_30d'].value_counts(normalize=False))\n",
    "print('\\nReadmission rate:', df['readmitted_30d'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ee1bf",
   "metadata": {
    "id": "9f2ee1bf"
   },
   "source": [
    "## Step 2: Preprocessing pipeline (encoding and scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779074f",
   "metadata": {
    "id": "0779074f"
   },
   "source": [
    "Define ColumnTransformer and pipeline.\n",
    "\n",
    "Run this cell to define the preprocessing pipeline for your readmission model. Numeric features will be standardized, and categorical variables will be one-hot encoded. This ensures all inputs are properly scaled and formatted before training the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec85a5",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1765474950612,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "75ec85a5"
   },
   "outputs": [],
   "source": [
    "# Preprocessing setup\n",
    "numeric_features = ['age','comorbidity_count','length_of_stay','num_prior_admissions']\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['sex','discharge_destination','lab_abnormal_flag']\n",
    "# lab_abnormal_flag is binary but treat as categorical for one-hot simplicity\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc3ce3",
   "metadata": {
    "id": "65dc3ce3"
   },
   "source": [
    "## Step 3: Train/Test split and baseline logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d3c23",
   "metadata": {
    "id": "ec4d3c23"
   },
   "source": [
    "Train model with class weights.\n",
    "\n",
    "Run this code to split your dataset into training and test sets, preserving the readmission class balance. You’ll then fit a baseline logistic regression model with class weighting to account for the imbalanced outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5f1b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765474953620,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "c5a5f1b6",
    "outputId": "0a3e1d6a-d6e6-4c76-8674-0804343b91b0"
   },
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X = df.drop(columns=['patient_id','readmitted_30d'])\n",
    "y = df['readmitted_30d']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Baseline logistic regression with class weight to handle imbalance\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('clf', LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42))])\n",
    "model = clf.fit(X_train, y_train)\n",
    "print('Model trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee54361",
   "metadata": {
    "id": "eee54361"
   },
   "source": [
    "## Step 4: Evaluate model - ROC, AUC, and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1b224",
   "metadata": {
    "id": "46c1b224"
   },
   "source": [
    "Plot ROC and compute AUC.\n",
    "\n",
    "Run this cell to generate predictions from your logistic regression model and evaluate its performance. You’ll compute predicted probabilities, plot the ROC curve with AUC, and review the confusion matrix and classification report at a 0.5 threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bfb2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1765474957036,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "d50bfb2d",
    "outputId": "0130a401-f811-4a99-e7cd-e94b1e52a138"
   },
   "outputs": [],
   "source": [
    "# Predictions and probabilities\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ROC and AUC\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print('AUC:', round(auc,3))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f'AUC={auc:.3f}')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix at 0.5 threshold\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix (0.5 threshold):\\n', cm)\n",
    "print('\\nClassification report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304a329",
   "metadata": {
    "id": "c304a329"
   },
   "source": [
    "## Step 5: Calibration and thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10d28f",
   "metadata": {
    "id": "fc10d28f"
   },
   "source": [
    "Calibration curve and choose threshold for clinical use.\n",
    "\n",
    "Run this code to evaluate how well your model’s predicted probabilities align with real outcomes. You’ll generate a calibration curve to assess probability accuracy and then compare key performance metrics—Precision (PPV) and Sensitivity—across multiple decision thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c168bb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1765474961358,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "6c168bb2",
    "outputId": "16f28ba0-2969-41dc-8a87-468d38d861f4"
   },
   "outputs": [],
   "source": [
    "# Calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration plot')\n",
    "plt.show()\n",
    "\n",
    "# Explore different thresholds\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "for t in thresholds:\n",
    "    pred_t = (y_prob >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred_t).ravel()\n",
    "    ppv = tp/(tp+fp) if (tp+fp)>0 else 0\n",
    "    sens = tp/(tp+fn) if (tp+fn)>0 else 0\n",
    "    print(f'Threshold {t}: PPV={ppv:.3f}, Sensitivity={sens:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3cee6",
   "metadata": {
    "id": "cdb3cee6"
   },
   "source": [
    "## Step 6: Address imbalance (oversampling) and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeff3b9",
   "metadata": {
    "id": "eeeff3b9"
   },
   "source": [
    "Use RandomOverSampler and retrain.\n",
    "\n",
    "Run this code to balance the training data using oversampling and retrain the logistic regression model. This helps the model learn from minority-class cases more effectively. After oversampling, you'll evaluate performance by computing the AUC on the untouched test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18251fc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1765474965886,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "18251fc0",
    "outputId": "84ef94c7-9520-42c5-c15e-8be3ff99fa9b"
   },
   "outputs": [],
   "source": [
    "# Oversampling training set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "print('Resampled class distribution:', pd.Series(y_res).value_counts())\n",
    "\n",
    "clf_res = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('clf', LogisticRegression(solver='liblinear', random_state=42))])\n",
    "model_res = clf_res.fit(X_res, y_res)\n",
    "y_prob_res = model_res.predict_proba(X_test)[:,1]\n",
    "print('AUC (resampled train):', round(roc_auc_score(y_test, y_prob_res),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b900d",
   "metadata": {
    "id": "6a3b900d"
   },
   "source": [
    "## Step 7: Interpretation and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3d5aa",
   "metadata": {
    "id": "3ac3d5aa"
   },
   "source": [
    "Coefficient interpretation and fairness checks.\n",
    "\n",
    "Run this code cell to extract and interpret the logistic regression model’s coefficients. You’ll generate a consolidated table showing each feature, its estimated coefficient, and the corresponding odds ratio—helping you understand how each variable influences the likelihood of 30-day readmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65115566",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1765474968771,
     "user": {
      "displayName": "Ramesh S",
      "userId": "12785615939781378195"
     },
     "user_tz": -330
    },
    "id": "65115566",
    "outputId": "8fb53616-29ce-4feb-c3fc-5dc03f991aaa"
   },
   "outputs": [],
   "source": [
    "# Coefficients interpretation\n",
    "feature_names_num = numeric_features\n",
    "# get one-hot feature names\n",
    "ohe = model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "ohe_features = list(ohe.get_feature_names_out(['sex','discharge_destination','lab_abnormal_flag']))\n",
    "feature_names = list(feature_names_num) + ohe_features\n",
    "coefs = model.named_steps['clf'].coef_[0]\n",
    "coef_df = pd.DataFrame({'feature': feature_names, 'coef': coefs})\n",
    "coef_df['odds_ratio'] = np.exp(coef_df['coef'])\n",
    "coef_df.sort_values('coef', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030993d",
   "metadata": {
    "id": "c030993d"
   },
   "source": [
    "## Consolidated practice exercises\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdaed3",
   "metadata": {
    "id": "9ecdaed3"
   },
   "source": [
    "### Exercise 1: Report class balance and compute baseline readmission rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a926a6",
   "metadata": {
    "id": "e2a926a6"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788c98f",
   "metadata": {
    "id": "b788c98f"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Use `df['readmitted_30d'].value_counts()` and `.mean()`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cea11a",
   "metadata": {
    "id": "36cea11a"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "print(df['readmitted_30d'].value_counts())\n",
    "print('Readmit rate:', df['readmitted_30d'].mean())\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e7ffe",
   "metadata": {
    "id": "4e0e7ffe"
   },
   "source": [
    "### Exercise 2: Build preprocessing pipeline and show transformed feature matrix shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58971899",
   "metadata": {
    "id": "58971899"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d06bdb",
   "metadata": {
    "id": "c2d06bdb"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Use the ColumnTransformer pipeline and call `preprocessor.fit_transform(X_train)`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee88787",
   "metadata": {
    "id": "aee88787"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "preprocessor.fit(X_train)\n",
    "Xt = preprocessor.transform(X_train)\n",
    "print('Transformed shape:', Xt.shape)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f67b60",
   "metadata": {
    "id": "21f67b60"
   },
   "source": [
    "### Exercise 3: Train logistic regression with class_weight='balanced' and report AUC on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4fb12",
   "metadata": {
    "id": "16f4fb12"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734a2e9",
   "metadata": {
    "id": "6734a2e9"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Fit pipeline and compute `roc_auc_score(y_test, y_prob)`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e31bb",
   "metadata": {
    "id": "7f1e31bb"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor), ('clf', LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42))])\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "print('AUC:', roc_auc_score(y_test, y_prob))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5431d9c",
   "metadata": {
    "id": "b5431d9c"
   },
   "source": [
    "### Exercise 4: Plot ROC curve and mark threshold at 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888b6ff",
   "metadata": {
    "id": "6888b6ff"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c72666",
   "metadata": {
    "id": "a8c72666"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Use `roc_curve` and plot, optionally mark point where threshold ~0.3.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea335f",
   "metadata": {
    "id": "a7ea335f"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.scatter(fpr[np.argmin(np.abs(thresholds-0.3))], tpr[np.argmin(np.abs(thresholds-0.3))], color='red')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37d0b0f",
   "metadata": {
    "id": "e37d0b0f"
   },
   "source": [
    "### Exercise 5: Compute calibration curve and comment if model is over- or under-confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb3707",
   "metadata": {
    "id": "45fb3707"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaae1c3",
   "metadata": {
    "id": "ceaae1c3"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Use `calibration_curve(y_test, y_prob, n_bins=10)` and inspect plot.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba1159",
   "metadata": {
    "id": "24ba1159"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "print(prob_true, prob_pred)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706e920",
   "metadata": {
    "id": "b706e920"
   },
   "source": [
    "### Exercise 6: Retrain using RandomOverSampler on training set and compare AUC to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fd3d8",
   "metadata": {
    "id": "0c0fd3d8"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e836808",
   "metadata": {
    "id": "0e836808"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Use `RandomOverSampler` to resample then fit and compute roc_auc_score on test set.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a5984",
   "metadata": {
    "id": "a99a5984"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "clf_res = Pipeline(steps=[('preprocessor', preprocessor), ('clf', LogisticRegression(solver='liblinear', random_state=42))])\n",
    "model_res = clf_res.fit(X_res, y_res)\n",
    "y_prob_res = model_res.predict_proba(X_test)[:,1]\n",
    "print('AUC (resampled):', roc_auc_score(y_test, y_prob_res))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb689d",
   "metadata": {
    "id": "37eb689d"
   },
   "source": [
    "### Exercise 7: List top 5 features by absolute coefficient (importance) and their odds ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3f994",
   "metadata": {
    "id": "3fa3f994"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbcdd5",
   "metadata": {
    "id": "acbbcdd5"
   },
   "source": [
    "<details> <summary>Click here for a hint</summary>\n",
    "\n",
    "Extract feature names and coefficients from trained model and sort by abs(coef).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d4818",
   "metadata": {
    "id": "442d4818"
   },
   "source": [
    "<details> <summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "feature_names = list(numeric_features) + list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(['sex','discharge_destination','lab_abnormal_flag']))\n",
    "coefs = model.named_steps['clf'].coef_[0]\n",
    "coef_df = pd.DataFrame({'feature':feature_names,'coef':coefs})\n",
    "coef_df['abs_coef']=coef_df['coef'].abs()\n",
    "coef_df['odds_ratio']=np.exp(coef_df['coef'])\n",
    "coef_df.sort_values('abs_coef',ascending=False).head(5)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2eec85",
   "metadata": {
    "id": "da2eec85"
   },
   "source": [
    "## Final thoughts and best practices\n",
    "\n",
    "- Logistic regression is a strong baseline that balances interpretability and performance.  \n",
    "- Check calibration and consider decision thresholds aligned with clinical priorities.  \n",
    "- Be explicit about bias and fairness checks across subgroups.  \n",
    "- Document preprocessing and model selection for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9efba9",
   "metadata": {
    "id": "ad9efba9"
   },
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have successfully completed this lab on **Predicting Readmission Risk with Logistic Regression**.\n",
    "\n",
    "In this lab, you built an end-to-end logistic regression workflow to predict 30-day hospital readmission using a simulated clinical dataset. You prepared the data with encoding, scaling, and a train/test split, then trained a logistic regression model with class-imbalance handling and regularization.\n",
    "\n",
    "You evaluated performance using ROC/AUC, confusion matrices, precision–recall curves, and calibration plots to judge probability accuracy. You also interpreted coefficients through odds ratios and conducted basic fairness and limitations checks relevant to clinical use.\n",
    "\n",
    "By the end, you practiced selecting thresholds for clinical decision-making, comparing baseline and oversampled models, and summarizing model results clearly and responsibly for clinicians.\n",
    "\n",
    "## Authors\n",
    "\n",
    "Ramesh Sannareddy\n",
    "\n",
    "Copyright © 2025 SkillUp. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8e89e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
